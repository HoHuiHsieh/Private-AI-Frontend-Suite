backend: "python"
max_batch_size: 0
input [
    {
        name: "query"
        data_type: TYPE_STRING
        optional: true
        dims: [ 1 ]
    },
    {
        name: "documents"
        data_type: TYPE_STRING
        optional: true
        dims: [ 1, -1 ]
    }
]
output [
    {
        name: "embeddings"
        data_type: TYPE_FP32
        dims: [ 1, -1 ]
    }
]

parameters {
    key: "model_path"
    value: {
        string_value: "google/embeddinggemma-300m"
    }
}
parameters {
    key: "device"
    value: {
        string_value: "cuda"
    }
}
parameters {
    key: "batch_size"
    value: {
        string_value: "1024"
    }
}

instance_group [
    {
        count: 1
        kind: KIND_CPU
    }
]